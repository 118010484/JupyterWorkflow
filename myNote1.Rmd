---
title: "R Notebook"
output:
  rmarkdown::github_document: default
  html_document:
    keep_md: yes
---

```{r}
data("AirPassengers")
AP <- AirPassengers
str(AP) # Time series with 144 values from years 1949 to 1961
# number of passenger in each month in each year = 112 118 129 ...
```

```{r}
ts(AP, frequency=12, start=c(1494,1)) # because we have monthly data from 1494 from January

```

```{r}
attributes(AP) # in a year we have 12 data points from year 1949 to 1960 something month
```

```{r echo=FALSE}
plot(AP)
```

The number of passengers are gradually going up. But there is also some amount of seasonality (there are periods of the year which are higher, some other periods are lower). This time series is definitely not stationary (THIS IS A PROBLEM)

## What can we do? Log transformation (to reduce fluctuations/std)
```{r}
AP <- log(AP)
plot(AP)
```

## Decomposition of additive time series
```{r}
decomp <- decompose(AP)
decomp$figure
```
-0.0858 for jan, -0.1144 for feb, etc.
```{r}
plot(decomp$figure,
     type="b",
     xlab='Month',
     ylab="Seasonality Index",
     col="blue",
     las = 2) # make the numbers appear vertical
```

Peaks at July. July has 20% more volume than average. November has 20% less volume than average

```{r}
plot(decomp)
```

trend captures the mean, seasonality captures the fluctuations pattern, random.

# 2nd video: ARIMA - Autoregressive Integrated Moving Average
## ACF & PACF Plots
## Ljung-Box Test
## Residual Plot
## Forecast
```{r}
#install.packages("forecast")
library(forecast)
# find BEST arima model based on AIC or BIC value
model <- auto.arima(AP)
model
```

The data used was AP. p (AR order) = 0, d (degree of differencing) = 1, q (Moving Average order) = 1

```{r}
attributes(model)
```
```{r}
model$coef
```

## ACF & PACF Plots
```{r}
acf(model$residuals, main="Correlogram")
```

The blue dotted lines are significant bounds. only lag 0 is outside the significant bounds.

```{r}
pacf(model$residuals, main="Partial Correlogram")
```

All lags are within the significant bounds.

## What if some lags ACF values are in the verge of violating the bounds??

## Ljung-Box Test
```{r}
Box.test(model$residuals, lag=20, type='Ljung-Box')
```
We are most interested in the p-value. If pv < 0.05, we can say there is a statistical significance. Since we got pv = 0.6, there is little evidence of non zero autocorrelation in the insample forecast errors at lags 1 to 20 (not violating the bounds)

## Residual Plot (to confirm no problem with the model)
```{r}
hist(model$residuals,
     col="red",
     xlab="Error",
     main = "Histogram of Residuals",
     freq = FALSE)
# It should be like normal distribution which is what we want
lines(density(model$residuals))

```

The model mimics the shape of std normal dist. We can be confident to move on to the forecasting.

## Forecasting
```{r}
f <- forecast(model, 48) # let's do forecasting for the next 48 months
library(ggplot2)
autoplot(f)
```

dark = 80% CI, light = 95% CI

```{r}
# calculate standard time series measure
accuracy(f)
```

# Video 3: Time Series Clustering
## Data Preparation, Calculate Distances, Hierarchical Clustering

```{r}
data <- read.table(file.choose(),header=F,sep="")
str(data)
```
```{r}
plot(data[,60]) # plot all rows, 60th column
```
This is time series data, we'll link the dots with lines
```{r}
plot(data[,60],type="l") # plot all rows, 60th column
```

We have 6 different patterns (0 to 100, 100 to 200, etc.)
```{r}
# Let's sample
j <- c(5,105,205,305,405,505)
sample <- t(data[j,])
plot.ts(sample,
        main = "Time-series Plot",
        col = "blue",
        type = "b")
```
## We need to prepare the data before clustering

```{r}

```



